# BertAdaptationMLM-NSP
Bert domain adaptation with target corpus by pretraining tasks (Masked Language Model &amp; Next Sentence Prediction). These codes uses huggingface ðŸ¤—transformers.
In this code, we execute domain adaptation with Japanese corpus.

# Require Environment
## Python modules
- Python: > 3.6.9
- transformers : 2.2.1
- pyknp :

## Others
- JUMAN++
